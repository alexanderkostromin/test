МИНИСТЕРСТВО НАУКИ И ВЫСШЕГО ОБРАЗОВАНИЯ РОССИЙСКОЙ ФЕДЕРАЦИИ

ФЕДЕРАЛЬНОЕ ГОСУДАРСТВЕННОЕ АВТОНОМНОЕ ОБРАЗОВАТЕЛЬНОЕ УЧРЕЖДЕНИЕ ВЫСШЕГО ОБРАЗОВАНИЯ
«НАЦИОНАЛЬНЫЙ ИССЛЕДОВАТЕЛЬСКИЙ ТЕХНОЛОГИЧЕСКИЙ УНИВЕРСИТЕТ «МИСиС»


Институт ИТКН
Кафедра инженерной кибернетики
Направление подготовки: 01.03.04 Прикладная математика
Квалификация (степень): бакалавр
Группа: БПМ-19-4 


ОТЧЕТ
ПО КУРСОВОЙ НАУЧНО-ИССЛЕДОВАТЕЛЬСКОЙ РАБОТЕ
на тему: 
«Разработка приложения на основе машинного обучения “МедСмарт”»
2022 – 2023 уч. год.

		Учащийся:                                                       /    Костромин А. Ю.                  / 
                                                 	                            подпись                                Фамилия И.О.  
                           
		    Оценка:           _________________________ 

                            Дата защиты: 15.05.23.
 
 
                            Руководитель КНИР 	                 / Старший преподаватель кафедры. Пышняк М. О.       / 
 	                                                               подпись     должность, уч., степень. Фамилия И.О.  
 


Москва 2023




Содержание отчета


1. Список используемых сокращений	4
2. Введение	5
2.1 Актуальность работы	5
2.2 Цели и задачи работы.	6
3. Аналитический обзор источников	7
3.1 Общий обзор применения машинного обучения в медицинской диагностике	7
3.1.1 Обзор COVID: Клинические характеристики и текущие методы диагностики	7
3.1.2 Обзор опухолей головного мозга: Клинические характеристики и текущие методы диагностики	8
3.1.3 Обзор рака молочных желез: Клинические характеристики и текущие методы диагностики	9
3.1.4 Обзор болезни Альцгеймера: Клинические характеристики и текущие методы диагностики	10
3.1.5 Обзор диабета: Клинические характеристики и текущие методы диагностики	11
3.1.6 Обзор сердечных заболеваний.  Клинические характеристики и текущие методы диагностики	12
3.2 Архитектура сверточных нейронных сетей	13
3.2.1 Сверточный слой	14
3.2.2 Слой активации	17
3.2.3 Слой подвыборки	20
3.2.4 Полносвязный слой	21
3.2.5 Слой нормализации данных	23
3.2.6 Слой выравнивания данных	24
3.2.7 Cлой прореживания	24
3.3 Алгоритмы оптимизации нейросетей	25
3.3.1 Градиентный спуск	25
3.3.2 Стохастический градиентный спуск	26
3.3.3 Adagrad	26
3.3.4 RMSProp	27
3.3.5 Adam	27
3.3.6 Классификатор на основе случайного леса	28
3.3.7 Математическая модель дерева принятия решений	31
3.3.8 XGBoost	33
4. Содержательная постановка задачи	37
5. Математическая постановка задачи.	38
6. Использование методов и средств информационных технологий	39
7. Проведенные исследования и анализ полученных результатов	40
7.1. Работа с данными	40
7.1.1 Поиск и формирование датасетов	40
7.2 Обучение моделей	40
7.3 Тестирование моделей	41
7.4 Разработка веб-приложения	41
8. Выводы	43
9. Список использованных источников	44
10. Приложения	45





















1. Список используемых сокращений

CNN - convultional neural network (сверточная нейронная сеть);
ML - machine learning (машинное обучение);
SVM - support vector machines (метод опорных векторов);
SMO - Sequential Minimal Optimization (алгоритм последовательной оптимизации);
5. СНС - сверточная нейронная сеть;
6. ADAM - ADAptive Momentum (Адаптивный момент)
7.  API - Application Programming Interface (программный интерфейс)







































2. Введение

2.1 Актуальность работы

В эпоху цифровой трансформации технологии машинного обучения и искусственного интеллекта все более активно интегрируются в различные сферы нашей жизни, включая здравоохранение. Применение этих технологий в медицине открывает новые возможности для улучшения качества и доступности медицинских услуг, что в свою очередь ведет к значительному повышению уровня здравоохранения в целом.

Объектом данной работы является область медицинской информатики, в частности применение машинного обучения и искусственного интеллекта в медицинских приложениях. Предметом исследования является разработка и применение медицинского приложения "Медсмарт", основанного на принципах машинного обучения.

Состояние вопроса на современном этапе свидетельствует о высоком уровне интереса к использованию машинного обучения в области медицинских технологий. Большинство исследований в этой области фокусируются на создании новых алгоритмов и моделей, которые могут быть использованы для анализа медицинских данных и предоставления более точных диагностических решений. Однако, несмотря на значительные успехи, разработка приложений, которые могли бы эффективно использовать эти алгоритмы и модели в реальных условиях, остается сложной задачей.

Исходные данные для разработки приложения "МедСмарт" были получены из нескольких источников, включая открытые медицинские базы данных и результаты собственного исследования. Были использованы современные методы машинного обучения для анализа этих данных и создания моделей, которые могут быть использованы в приложении.

Актуальность темы обусловлена растущей необходимостью в поиске новых подходов к диагностике и лечению болезней, улучшению качества и доступности медицинской помощи. В свете этого, разработка приложения "МедСмарт" на основе машинного обучения представляет собой важный шаг в направлении интеграции новейших технологий в медицинскую практику.

Новизна данной работы заключается в применении современных технологий машинного обучения для создания медицинского приложения. "МедСмарт" представляет собой уникальную платформу, способную обрабатывать и анализировать большие объемы медицинских данных для предоставления точных и оперативных медицинских решений.

В контексте текущих исследований, данная работа связывается с многими другими работами, посвященными применению машинного обучения в медицинской индустрии. Она вносит свой вклад в область медицинской информатики, расширяя понимание возможностей применения машинного обучения в медицинских приложениях.

В результате, данное исследование позволит получить более глубокое понимание процесса разработки медицинских приложений на основе машинного обучения и его потенциального влияния на сферу здравоохранения.

2.2 Цели и задачи работы.

Целью данной работы является разработка веб-приложения “МедСмарт”, которое будет способно диагностировать 7 различных заболеваний при помощи машинного обучения. Веб-приложение будет диагностировать следующие заболевания: Covid, опухоли головного мозга, рак молочных желез, болезнь Альцгеймера, сахарный диабет, пневмонию, сердечные заболевания. 

Чтобы достичь целевого результата, необходимо выполнить ряд задач:
Произвести обзор научной литературы;
Установить тип математической проблемы, которую следует решить для разработки алгоритма функционирования веб-приложения.
Уточнить модели машинного обучения и данные, которые необходимы для решения заданной математической проблемы.
Найти, обработать и подготовить данные для машинного обучения. 
Провести обучение выбранных моделей, настроить подходящие значения гиперпараметров и оценить эффективность их функционирования.
Разработать бакэнд приложения. 
Разработать пользовательский интерфейс. 
Написать фронтэнд приложения. 
Установить приложение на веб-сервер для того чтобы был доступ по сети.
Запустить веб-приложение и оценить его работу. 
































3. Аналитический обзор источников
3.1 Общий обзор применения машинного обучения в медицинской диагностике
Машинное обучение в последние годы привлекло значительное внимание в медицинской сфере, прежде всего в области диагностики заболеваний. Это обусловлено его способностью анализировать большие объемы данных и выявлять сложные взаимосвязи, которые могут оказаться недоступными для традиционных статистических методов.
Основные технологии машинного обучения, используемые в медицинской диагностике, включают сверточные нейронные сети и метод случайных лесов. Сверточные нейронные сети, в особенности, оказались особенно полезными при работе с изображениями, такими как медицинские сканирования, благодаря их способности автоматически выявлять и использовать наиболее важные признаки. Метод случайных лесов, с другой стороны, позволяет эффективно анализировать большое количество переменных и учитывать их взаимосвязи.
Применение машинного обучения в медицинской диагностике включает обнаружение и классификацию заболеваний, предсказание риска заболевания и оптимизацию лечебных стратегий. Все это делает машинное обучение мощным инструментом для улучшения точности диагностики и эффективности медицинского ухода.
Однако, несмотря на эти преимущества, применение машинного обучения в медицинской диагностике также представляет некоторые вызовы. Одним из них является необходимость в больших объемах качественных данных для обучения моделей. Кроме того, важно обеспечить интерпретируемость результатов, чтобы врачи и другие медицинские специалисты могли понять и использовать выводы, полученные с помощью машинного обучения. Наконец, важно учесть этические и юридические вопросы, связанные с использованием данных пациентов и их приватностью.

3.1.1 Обзор COVID: Клинические характеристики и текущие методы диагностики
COVID-19, вызванный коронавирусом SARS-CoV-2, представляет собой системное заболевание, которое впервые было идентифицировано в конце 2019 года и с тех пор стало глобальной пандемией, серьезно затронувшей все сферы общественной жизни. Это заболевание проявляется широким спектром симптомов, включая лихорадку, кашель, утомляемость, потерю обоняния и вкуса, одышку и в некоторых случаях тяжелое респираторное заболевание.
С момента появления COVID-19 было разработано множество методов диагностики. Полимеразная цепная реакция (ПЦР) является наиболее распространенным и надежным методом, используемым для обнаружения активной инфекции. Этот метод основан на амплификации и детекции вирусной РНК и требует специализированных лабораторных условий и обученного персонала. Быстрый тест на антигены, который также может обнаруживать активную инфекцию, представляет собой более простую и более быструю альтернативу, но его чувствительность и специфичность обычно ниже, чем у ПЦР.
Методы диагностики на основе изображений, такие как КТ и рентген грудной клетки, могут быть использованы для оценки степени поражения легких и прогнозирования исхода заболевания. Однако эти методы имеют свои ограничения, включая излучение для пациента, стоимость и доступность, а также сложность интерпретации изображений.
В этом контексте машинное обучение может предложить новые возможности для улучшения диагностики COVID-19. Этот подход может привести к разработке автоматизированных систем, способных анализировать медицинские изображения или другие типы данных, такие как клинические параметры или результаты лабораторных тестов, для предсказания наличия или отсутствия COVID-19, а также для оценки тяжести заболевания или прогнозирования исхода.

3.1.2 Обзор опухолей головного мозга: Клинические характеристики и текущие методы диагностики
Опухоли головного мозга - это сложный и разнообразный класс заболеваний, которые включают в себя широкий спектр типов опухолей, относительно доброкачественных, таких как менингиомы, до агрессивных злокачественных форм, включая глиобластомы. Симптомы могут включать головную боль, нарушения зрения, проблемы с координацией, изменения личности или психического состояния, приступы и другие неврологические проблемы. Однако эти симптомы часто неспецифичны и могут быть вызваны многими другими причинами, что затрудняет диагностику.
Текущие методы диагностики опухолей мозга включают магнитно-резонансную томографию (МРТ), компьютерную томографию (КТ), позитронно-эмиссионную томографию (ПЭТ), а также биопсию для гистологического анализа. МРТ является основным инструментом для визуализации опухолей мозга, позволяя детально изучить их размер, форму, расположение и взаимодействие с окружающими тканями. Однако интерпретация изображений МРТ может быть сложной и требует опыта и знаний. Биопсия предоставляет дополнительную информацию о типе и стадии опухоли, но является инвазивной процедурой и не всегда возможной или безопасной.
В этом контексте применение машинного обучения может значительно облегчить и ускорить диагностику опухолей головного мозга. Сверточные нейронные сети (CNN) и методы случайных лесов могут быть использованы для анализа изображений МРТ, автоматического определения наличия, размера, формы и местоположения опухоли, а также для предсказания ее типа и стадии на основе изображений и других клинических данных. Это может улучшить точность и эффективность диагностики, сократить время на анализ изображений и уменьшить зависимость от индивидуального опыта и субъективных оценок специалистов. Однако, важно отметить, что эти методы машинного обучения должны быть тщательно проверены и валидированы на больших и разнообразных наборах данных, прежде чем они могут быть широко применены в клинической практике. Кроме того, их использование должно быть встроено в более широкий контекст медицинской диагностики, включая клиническую оценку и другие методы исследования.
3.1.3 Обзор рака молочных желез: Клинические характеристики и текущие методы диагностики

Распространенность рака молочной железы ставит его на первое место среди всех видов рака у женщин. Он проявляется через уплотнения в груди, изменение формы груди, втяжение кожи или соска, и нередко сопровождается кровянистыми выделениями из соска.
Для его диагностики существуют различные подходы, включая маммографию, ультразвук, магнитно-резонансную томографию и биопсию. Маммография применяется как основной скрининговый метод, но у женщин с плотными молочными железами она может быть менее чувствительной. Биопсия позволяет установить более точный диагноз, определяя тип и стадию рака.

Вместе с этим, на передний план выходят методы машинного обучения. Использование сверточных нейронных сетей и метода случайных лесов может значительно улучшить точность диагностики. Они способны к анализу изображений маммографии и МРТ, автоматическому выявлению подозрительных областей и оценке вероятности их злокачественности.
Также, эти методы могут применяться для анализа гистологических изображений биопсии, предсказывая возможное течение болезни. Однако, важность их тщательной проверки и валидации не может быть недооценена. Безопасность данных, справедливость и прозрачность принятия решений также являются ключевыми вопросами при использовании алгоритмов машинного обучения в медицинской диагностике.

3.1.4 Обзор болезни Альцгеймера: Клинические характеристики и текущие методы диагностики

Болезнь Альцгеймера – это прогрессирующее нейродегенеративное заболевание, приводящее к деменции. Оно характеризуется постепенной потерей памяти, способностей к обучению, речи и пространственной ориентации. Часто сопровождается изменениями в поведении и личности. Сегодня болезнь Альцгеймера является наиболее распространенной причиной деменции у пожилых людей.
Диагностика болезни Альцгеймера включает медицинский осмотр, нейропсихологическое тестирование, анализ крови, МРТ головного мозга и, в некоторых случаях, пункцию спинномозговой жидкости. Однако диагноз остается сложным из-за отсутствия специфичных биомаркеров и сходства симптомов с другими нейродегенеративными заболеваниями.
В последние годы внимание исследователей привлекают возможности машинного обучения для диагностики болезни Альцгеймера. Применение алгоритмов, таких как сверточные нейронные сети и метод случайных лесов, обещает улучшить точность и раннюю диагностику этого заболевания.
Основываясь на данных МРТ, эти модели могут обучаться распознаванию паттернов, характерных для болезни Альцгеймера. Они также могут анализировать сложные сочетания биомаркеров и других параметров для прогнозирования риска развития болезни.
Однако, несмотря на значительный потенциал, использование машинного обучения для диагностики болезни Альцгеймера еще требует дополнительных исследований. Важно обеспечить точность и надежность таких систем, а также их способность работать с реальными клиническими данными.

3.1.5 Обзор диабета: Клинические характеристики и текущие методы диагностики

Диабет – это хроническое заболевание, при котором организм не может эффективно использовать глюкозу, полученную из пищи. Диабет обычно классифицируется как Тип 1 и Тип 2. При диабете 1-го типа поджелудочная железа не производит достаточное количество инсулина, а при диабете 2-го типа организм не способен эффективно использовать инсулин, который он производит.
Клинические симптомы диабета включают повышенную утомляемость, частые мочеиспускания, постоянную жажду, замедленное заживление ран и инфекций, изменения в зрении и непояснимую потерю веса.
Текущие методы диагностики диабета включают измерение уровня глюкозы в крови натощак, проведение теста на глюкозотолерантность и измерение уровня гликированного гемоглобина (HbA1c). Однако эти тесты могут быть сложными, требуют медицинского наблюдения и не всегда точны.
В этом контексте машинное обучение предлагает новые подходы к диагностике и мониторингу диабета. Сверточные нейронные сети и метод случайных лесов могут использоваться для анализа больших наборов данных, включая клинические данные, данные об образе жизни и генетические данные, чтобы предсказать риск развития диабета или оценить его прогрессию.
Например, некоторые исследования показали, что алгоритмы машинного обучения могут предсказать развитие диабета на основе ряда клинических и демографических данных с высокой точностью. Это может помочь в раннем выявлении заболевания и вовременном начале лечения.
Тем не менее, применение машинного обучения в диагностике диабета все еще находится в стадии развития, и требуется больше исследований для улучшения этих технологий и их интеграции в медицинскую ппрактику. Эффективность такого подхода также будет зависеть от доступности и качества данных, а также от способности алгоритмов машинного обучения обрабатывать сложные и непостоянные шаблоны данных.
В заключение, исходя из обзора литературы и существующих исследований, можно сделать вывод о потенциале и важности машинного обучения в современной диагностике диабета. Это открывает новые горизонты для улучшения качества жизни пациентов с диабетом и может стать ключевым инструментом для прогнозирования и диагностики данного заболевания в будущем.


3.1.6 Обзор сердечных заболеваний.  Клинические характеристики и текущие методы диагностики

В современном медицинском мире сердечно-сосудистые заболевания продолжают оставаться основной причиной смертности и инвалидности на глобальном уровне. Часто они характеризуются сложным ходом и требуют комплексного подхода к диагностике и лечению.
Сегодняшние методы диагностики включают широкий спектр техник, начиная от физического осмотра и заканчивая сложными инвазивными процедурами. Среди них - электрокардиограмма (ЭКГ), УЗИ сердца, коронарография и многие другие. Однако каждый из этих методов имеет свои ограничения и не всегда позволяет достичь точной диагностики.
В это усложненное поле входят методы машинного обучения, предлагая свежие и инновационные подходы к проблеме. Используя алгоритмы, которые могут изучать и обрабатывать большое количество данных, машинное обучение может помочь обнаружить скрытые взаимосвязи и модели в диагностических данных, которые могут быть не доступны для традиционного анализа.
Несмотря на большой потенциал, использование машинного обучения в диагностике сердечно-сосудистых заболеваний все еще находится в стадии активного исследования. Существуют важные вопросы, которые требуют внимания, включая выбор подходящих алгоритмов, сбор и обработка данных, а также этические и правовые вопросы, связанные с использованием искусственного интеллекта в медицине.
В результате, применение машинного обучения в области сердечно-сосудистых заболеваний является перспективным направлением исследований, которое может внести значительный вклад в улучшение качества диагностики и лечения этих заболеваний в будущем.
3.2 Архитектура сверточных нейронных сетей

Сверточная нейронная сеть (Convolutional Neural Network или сокращенно CNN) - это тип нейронных сетей, используемый для обработки изображений, видео и других многомерных данных, которые имеют локальную структуру. Основная идея этого типа нейронных сетей заключается в том, что они используют свойства пространственной связности между пикселями изображения для определения форм, контуров и текстур, которые присутствуют на изображении. Основная особенность данной нейросети заключается в том, что в нем используется слой свертки. Свертка - это процесс применения ядра свертки к картам признаков для выявления определенных шаблонов. Ядро свертки представляет собой матрицу с весами, которая скользит по изображению, попиксельно умножаясь на пиксели изображения, и суммируя результаты. Веса свертки заранее неизвестны, они формируются в процессе обучения методом обратного распространения ошибки. Результат такой операции - это карта признаков, которая хранит информацию о наличии определенных шаблонов на изображении.

Рис 1. Общая схема работы сверточной нейронной сети
Архитектура сверточной нейросети всегда состоит из нескольких слоев. Самые основные из них: 
1. Слой свертки (Convolution Layer) - в этом слое выполняется самый важный шаг - свертка ядром свертки с исходным изображением. 
2. Слой активации (Activation Layer) - после слоя свертки следует слой активации, который применяет нелинейное преобразование к выходу из слоя свертки, чтобы вводить нелинейности в модель. 
3. Слой подвыборки (Pooling Layer) - этот слой уменьшает размер карт признаков, путем уменьшения количества пикселей их усреднением или выбором максимальных значений. 
4. Слой полносвязной нейронной сети (Fully Connected Layer) - этот слой соединяет выходные данные слоев свертки с выходными данными, готовыми для классификации в конечном слое. 
В сверточных нейронных сетях часто используются различные типы слоев, такие как Normalization Layer, Dropout Layer и другие. Эти типы слоев используются для предотвращения переобучения модели и повышения ее производительности. Математически сверточная нейронная сеть состоит из нескольких матричных операций, включая операцию свертки, обратную операцию (как правило - reverse convolution или transposed convolution), матричное умножение и уменьшение размерности. Принципы работы сверточной нейросети включают подачу входных данных в нейронную сеть, последовательное прохождение через слои нейронной сети с использованием операций свертки, уплотнения и матричного умножения, и получение выходных данных сверточной нейросети.
3.2.1 Сверточный слой
Сверточный слой является фундаментальным строительным блоком сверточных нейронных сетей (CNN). Он предназначен для уменьшения объема данных и создания карт признаков. Математический принцип, лежащий в основе сверточного слоя, — это свертка, представляющая собой математическую операцию, объединяющую две функции для получения третьей функции. В сверточной нейронной сети операция свертки применяется к входным данным и обучаемым весам, называемым ядрами или фильтрами. Операция свертки включает скольжение ядра по входным данным и вычисление скалярного произведения между ядром и входными данными в каждой позиции. Размерность ядра фильтра выбирают обычно квадратной формы с нечетным количеством элементов вдоль осей матрицы: 3, 5, 7 и т.д. Результатом операции свертки в каждой позиции является одно число, которое показывает, насколько хорошо ядро ​​соответствует входным данным в этой позиции. Например, мы имеем фильтр размерностью 2 x 2 (матрица k) и он делает проекцию на исходное изображение, которая тоже имеет размерность 2 x 2 (матрица n), тогда значение выходного слоя вычисляется следующим образом:

Эта операция называется скалярным произведением
Результат операции свертки часто называют картой объектов, представляющей собой представление входных данных, в котором выделяются определенные функции, важные для рассматриваемой задачи. Принцип формирования выходного сверточного слоя:

Рис. 2. Процесс формирования выходного сверточного слоя
Размерность выходного сверточного слоя:

Каждое ядро ​​может научиться обнаруживать разные функции во входных данных. Например, ядро ​​может научиться обнаруживать края или углы изображения. Сверточный слой обычно имеет несколько ядер, каждое из которых учится обнаруживать разные функции во входных данных. Выходные данные всех ядер складываются для создания трехмерного тензора, который является выходным сигналом сверточного слоя. Размер выходного тензора зависит от размера входного тензора, размера ядер, шага (т. е. расстояния, которое ядро ​​перемещает между каждым вычислением) и заполнения (т. входного тензора). Выходной тензор часто меньше входного тензора, поэтому слои объединения часто используются для уменьшения размерности карт объектов. В целом, сверточный слой является ключевым компонентом сверточных нейронных сетей и позволяет сети изучать и извлекать признаки из входных данных способом, устойчивым к перемещению, вращению и масштабированию. 

В языке Python сверточный слой кодируется следующим образом:
tf.keras.layers.Conv2D(
    filters,
    kernel_size,
    strides=(1, 1),
    padding="valid",
    data_format=None,
    dilation_rate=(1, 1),
    groups=1,
    activation=None,
    use_bias=True,
    kernel_initializer="glorot_uniform",
    bias_initializer="zeros",
    kernel_regularizer=None,
    bias_regularizer=None,
    activity_regularizer=None,
    kernel_constraint=None,
    bias_constraint=None,
    **kwargs
)
Разберём подробно самые важные параметры сверточного слоя:
filters – параметр, задающий глубину тензора. Это значит, что ядро свертки “пройдется” по всему изображению некоторое число раз и составит свою выходную карту признаков.  Эта карта имеет вид одномерного вектора с числом признаков filters. Все эти векторы объединяются в выходной тензор слоя. При этом ядра свертки не определяются человеком заранее, они формируются самостоятельно во время обучения методом обратного распространения ошибки.
kernel_size – размер ядра свертки, который ‘скользит’ пиксель за пикселем по исследуемому тензору. Обычно квадратная матрица, но можно, передав кортеж, задать прямоугольную
strides – шаг свертки. По умолчанию равен единице. Мы можем присвоить этому параметру либо одно целое число – шаг одинаков и по ширине, и по высоте, либо кортеж, в котором указать разные шаги свертки по ширине и высоте
padding – заполнение. Данный параметр используется во избежание эффекта границ. Рассмотрим карту признаков 5 x 5. Существует лишь 9 позиций, куда может поместиться ядро свертки 3 х 3. Следовательно, карта выходных признаков также будет иметь размер 3 х 3:

Рис 3. Карта входных и выходных признаков без дополнения
Чтобы получить выходную карту признаков с теми же пространственными размерами, что и входная карта, можно использовать дополнение (padding). Дополнение заключается в добавлении соответствующего количества строк и столбцов с каждой стороны входной карты признаков, чтобы можно было поместить центр окна свертки в каждую входную клетку. Для окна 3 × 3 нужно добавить один столбец справа, один столбец слева, одну строку сверху и одну строку снизу. Для окна 5 × 5 нужно добавить две строки:

Рис 4. Карта входных и выходных признаков с дополнением

Таким образом, при значении параметра padding = ‘value’ (значение по умолчанию), карта признаков остается исходной. При значении padding = ‘same’ выходная карта признаков дополняется таким образом, чтобы её размерность совпадала с входной картой.
activation – функция активации, которая используется для преобразования выходных данных. 
3.2.2 Слой активации
Слой активации, также известный как функция активации, является важным компонентом нейронных сетей. Это нелинейная функция, которая применяется к выходу каждого нейрона в слое нейронной сети. Цель слоя активации — ввести нелинейность в нейронную сеть, что позволяет ей моделировать сложные нелинейные отношения между входами и выходами. Существует множество различных типов функций активации, каждый из которых имеет свои сильные и слабые стороны. Однако все функции активации имеют некоторые общие принципы. 
Первый принцип активационного слоя состоит в том, что он должен быть дифференцируемым. Это связано с тем, что обратное распространение, алгоритм, используемый для обучения нейронных сетей, основан на способности вычислять градиенты функции потерь по отношению к весам и смещениям в сети. Если функция активации не дифференцируема, то нельзя использовать обратное распространение для обновления весов и смещений, что делает невозможным обучение сети. 
Второй принцип активационного слоя заключается в том, что он должен иметь возможность насыщаться. Насыщение относится к явлению, когда выход функции активации застревает на определенном значении даже при изменении входа. Если функция активации не насыщается, то выход нейрона может неограниченно расти, что затрудняет обучение сети. Однако если функция активации насыщается слишком сильно, то градиенты могут стать очень маленькими, что замедляет обучение. 
Третий принцип уровня активации заключается в том, что он должен быть вычислительно эффективным. Это важно, потому что нейронные сети могут иметь миллионы или даже миллиарды параметров, поэтому каждая операция должна быть максимально эффективной, чтобы свести к минимуму время обучения и использование памяти. 
Рассмотрим некоторые из наиболее часто используемых функций активации и то, как они воплощают эти принципы. 
1. Функция активации сигмоида: (sigmoid)
Сигмовидная функция активации определяется следующим уравнением: 
 
Эта функция сопоставляет любое входное значение с числом от 0 до 1, что делает ее полезной для задач, связанных с двоичной классификацией. Сигмоидная функция также дифференцируема, что делает ее совместимой с обратным распространением. Однако сигмоидная функция может страдать от насыщения. Когда входное значение очень велико или очень мало, выход сигмовидной функции приближается к 0 или 1 соответственно. Это означает, что градиенты в этих областях могут стать очень маленькими, что замедляет обучение. 
2. Функция активации ReLU: (relu)
Функция активации ReLU, сокращение от выпрямленной линейной единицы, определяется следующим уравнением: 
 
Эта функция просто возвращает входное значение, если оно положительное, и 0 в противном случае. Функция ReLU эффективна в вычислительном отношении, поскольку требует только простой операции сравнения. Функция ReLU также не страдает от насыщения так же, как сигмовидная функция. Однако он может страдать от проблемы, известной как проблема «умирающего ReLU», когда выход нейрона постоянно застревает на 0. Это может произойти, когда входное значение функции ReLU отрицательное, что приводит к тому, что градиент равен 0. и предотвращает обновление весов во время тренировки. Чтобы смягчить эту проблему, исследователи предложили варианты функции ReLU, такие как негерметичный ReLU и параметрический ReLU. 
3. Функция активации гиперболический тангенс: (tanh) 
Функция активации тангенса определяется следующим уравнением: 

Эта функция сопоставляет любое входное значение с числом от -1 до 1, что делает ее полезной для задач, связанных с классификацией более чем двух классов. Функция tanh также дифференцируема, что делает ее совместимой с обратным распространением. Функция тангенса страдает от той же проблемы насыщения, что и сигмовидная функция, но в меньшей степени. Это означает, что градиенты могут стать маленькими, но не такими маленькими, как с сигмовидной функцией. 
4. Функция активации Softmax: (softmax)
Функция активации softmax определяется следующим уравнением:
 
Эта функция сопоставляет любое входное значение с распределением вероятностей по нескольким выходным классам. Функция softmax часто используется в качестве конечной функции активации в нейронных сетях для задач классификации нескольких классов. Функция softmax вычислительно эффективна и дифференцируема. Он также не страдает от насыщения, как сигмоидная функция или функция гиперболического тангенса. 
В языке Python слой активации кодируется следующим образом:
tf.keras.layers.Activation(activation, **kwargs)

activation – параметр, задающий функцию активации

В заключение, активационный слой является важнейшим компонентом нейронных сетей, который вносит нелинейность в модель. Различные типы функций активации воплощают разные принципы, такие как дифференцируемость, насыщенность и вычислительная эффективность.

3.2.3 Слой подвыборки
Слой подвыборки уменьшает размер карт признаков, путем уменьшения количества пикселей их усреднением или выбором максимальных значений. Это помогает упростить и сжать информацию, содержащуюся в этих картах объектов, что позволяет быстрее и эффективнее обрабатывать данные. После того, как сверточный слой сгенерировал свой набор карт объектов, в дело включается слой подвыборки. Этот слой берет каждую карту объектов и делит ее на ряд неперекрывающихся прямоугольных областей, обычно называемых объединяющими областями или объединяющими окнами. Затем для каждой области объединения слой выводит максимальное значение, найденное в этой области. Это максимальное значение становится новым значением для этой конкретной области в выходных данных слоя подвыборки. Рассмотрим пример с изображением 4 х 4. Размер матрицы составляет 2 х 2, шаг матрицы равен двум:

Рис 5. Сокращение размера матрицы путем выбора максимального значения и пула
Процесс получения максимального значения в области объединения называется максимальным объединением и имеет ряд важных преимуществ. Во-первых, это помогает уменьшить пространственное разрешение карт объектов, что может помочь предотвратить переоснащение и повысить эффективность последующих слоев в сети. Кроме того, это помогает создать форму инвариантности перевода, а это означает, что точное расположение конкретной функции на изображении становится менее важным. Чтобы понять, как максимальное объединение помогает создать инвариантность перевода, рассмотрим следующий пример. Представим, что конкретный объект расположен в верхнем левом углу входного изображения. Если бы CNN использовала только сверточные слои и не включала бы какие-либо слои субдискретизации, то эта функция активировалась бы только в том случае, если бы она появлялась в верхнем левом углу любых последующих изображений, обрабатываемых сетью. Однако, если в сеть включен слой максимального пула, то точное местоположение объекта становится менее важным. Пока функция присутствует где-то в области объединения, сеть распознает ее и извлечет ее максимальное значение. 
Существует ряд различных гиперпараметров, которые можно настроить в слое подвыборки. Во-первых, это размер окна пула. Общие размеры включают 2x2, 3x3 и 4x4, хотя технически можно использовать любой размер. Чем больше окно объединения, тем выше степень субдискретизации. Однако большие окна пула также могут привести к потере большего количества информации, поэтому необходимо учитывать компромисс. Другим гиперпараметром является шаг, который определяет размер шага, который принимает окно пула при перемещении по карте объектов. Шаг 1 означает, что окно объединения перемещается на один пиксель за раз, а шаг 2 означает, что оно перемещается на два пикселя за раз и так далее. Больший шаг приводит к более агрессивной подвыборке, поскольку учитывается меньше областей объединения. Однако слишком большой шаг может привести к потере важной информации. Наконец, слой подвыборки также может включать параметры заполнения. Заполнение включает в себя добавление дополнительных пикселей по краям карты объектов, что может помочь гарантировать, что края изображения правильно захватываются окнами объединения. Существует два основных типа отступов: действительный отступ, который не требует дополнительных отступов, и такой же отступ, который добавляет достаточно отступов, чтобы гарантировать, что выходная карта объектов имеет те же пространственные размеры, что и входная карта объектов. Таким образом, уровень субдискретизации слоя подвыборки является важным компонентом многих CNN. Его основная цель — уменьшить пространственное разрешение карт объектов, созданных сверточными слоями, что может помочь предотвратить переоснащение и повысить эффективность более поздних слоев. Слой достигает этого, разделяя каждую карту объектов на серию объединенных окон и выводя максимальное значение, найденное в каждом окне. Это помогает создать форму инвариантности перевода и может помочь упростить информацию, содержащуюся в картах объектов. Настраивая гиперпараметры данного слоя, разработчики CNN могут контролировать степень субдискретизации и адаптировать слой к своим конкретным потребностям.

В языке Python слой активации кодируется следующим образом:
tf.keras.layers.MaxPooling2D(
    pool_size=(2, 2), strides=None, padding="valid", data_format=None, **kwargs
)
pool_size – размер пула
strides – шаг хода
padding – параметры заполнения

3.2.4 Полносвязный слой
Полносвязный слой является одним из наиболее важных слоев в устройстве нейронных сетей. Этот слой называется так, поскольку каждый из нейронов в слое связан с каждым другим нейроном в предыдущем слое, а также с каждым нейроном в следующем слое. Слой может быть использован как для создания полностью связанных нейронных сетей, так и для добавления связей между существующими слоями в сети. 
Принцип работы этого слоя сводится к следующим шагам: 
1. Сначала данные принимаются на вход слоя, который может содержать определенное число нейронов. Каждый нейрон в слое представляет собой отдельный узел, который обрабатывает определенную часть входных данных
2. На вход каждого нейрона поступают сигналы от всех нейронов в предыдущем слое. Для каждого входного сигнала весовой коэффициент рассчитывается автоматически в процессе обучения нейронной сети. Получаем состояние нейрона:

Где n – число входов нейрона, xi – значение i-го входа нейрона, wi – вес i-го значения
3. Затем нейрон производит вычисления на основе входных сигналов и соответствующих весовых коэффициентов. Выходные данные каждого нейрона передаются на вход следующего слоя. Их можно задать общей формулой:

Где output – выходные данные нейрона, input – входные данные, weights – тензор весов, bias – тензор смещения, f – функция активации
4. Все выходные данные из всех нейронов полносвязного слоя объединяются в один массив, который и будет являться выходом слоя.
В языке Python слой активации кодируется следующим образом:
tf.keras.layers.Dense(
    units,
    activation=None,
    use_bias=True,
    kernel_initializer="glorot_uniform",
    bias_initializer="zeros",
    kernel_regularizer=None,
    bias_regularizer=None,
    activity_regularizer=None,
    kernel_constraint=None,
    bias_constraint=None,
    **kwargs
)
Основные параметры, которые задает человек:

units – размерность выходного вектора
activation – функция активации
use_bias – учитывать ли вектор смещения или нет

3.2.5 Слой нормализации данных
BatchNormalization (BN) - это слой нормализации, который применяет стандартные преобразования активации на входных данных, чтобы улучшить стабильность и скорость сходимости обучения нейронных сетей. 
Он очень эффективен при обучении глубоких нейронных сетей, где градиенты могут затухать или взрывно возрастать при передаче через многослойные сети, что приводит к проблеме обучения. BN применяется к выходу каждого слоя и нормализует этот выход путем вычитания среднего и деления на стандартное отклонение всех входных моментов в мини-батч. Таким образом, среднее значение каждой активации равно 0, а стандартное отклонение равно 1. Это обеспечивает лучшую устойчивость к обучению и быстроту сходимости в процессе обучения. Математический метод, используемый в BN, можно представить следующим образом: 
Для каждой активации “a” в мини-батче: 
- Вычисляем среднее значение μ и стандартное отклонение σ по всему мини-батчу. 
- Нормализуем данные a: 
 
где ε - это небольшое число, используемое для предотвращения деления на 0 и вычисляется как  10-5 или 10-6
- Применяем масштабирование и сдвиг: . 
где γ и β - это параметры, которые оптимизируются в процессе обучения нейронной сети. Использование слоя BatchNormalization позволяет достичь более высокой точности при обучении нейронных сетей, а также ускоряет процесс обучения за счет более быстрой сходимости и устойчивости к обучению.
В языке Python слой нормализации кодируется следующим образом:
tf.keras.layers.BatchNormalization(
    axis=-1,
    momentum=0.99,
    epsilon=0.001,
    center=True,
    scale=True,
    beta_initializer="zeros",
    gamma_initializer="ones",
    moving_mean_initializer="zeros",
    moving_variance_initializer="ones",
    beta_regularizer=None,
    gamma_regularizer=None,
    beta_constraint=None,
    gamma_constraint=None,
    synchronized=False,
    **kwargs
)
axis – ось, по которой будет производиться нормировка. Обычно указывается самая последняя
beta_initializer – начальное значение коэффициента бета
gamma_initializer – начальное значение коэффициента гамма
epsilon – добавочное слагаемое, предотвращающее деление на ноль
При данных настройках этот слой нормализует данные таким образом, чтобы среднее было равно 0, а стандартное отклонение - 1

3.2.6 Слой выравнивания данных
Слой выравнивания данных в нейросетях используется для представления входного тензора в виде одномерного вектора. Этот слой не изменяет размерность тензора, а просто вытягивает все элементы в него.
Принцип работы слоя выравнивания следующий:
1. Принимает входной тензор любой размерности.
2. Вытягивает все элементы этого тензора в одномерный вектор.
3. Возвращает одномерный вектор.
Например, если на вход подается тензор размерности (3, 4, 5), то слой вытянет его в одномерный вектор размерности (60).
Слой выравнивания часто используется после сверточных слоев в нейронных сетях для представления результатов свертки в виде одномерного вектора перед передачей в полносвязную часть сети. Это упрощает обработку данных и уменьшает количество параметров в сети.
В языке Python слой выравнивания кодируется следующим образом:
tf.keras.layers.Flatten(data_format=None, **kwargs)

3.2.7 Cлой прореживания
Прореживание — один из наиболее эффективных и распространенных приемов регуляризации для нейронных сетей, разработанный в Университете Торонто. Прореживание, которое применяется к слою, заключается в удалении (присваивании нуля) случайно выбираемым признакам на этапе обучения с целью избегания переобучения модели
Представим, что в процессе обучения некоторый уровень для данного образца на входе в нормальной ситуации возвращает вектор [0,2, 0,5, 1,3, 0,8, 1,1]. После применения прореживания некоторые элементы вектора получают нулевое значение: например, [0, 0,5, 1,3, 0, 1,1]. Коэффициент прореживания — это доля обнуляемых признаков; обычно он выбирается в диапазоне от 0,2 до 0,5. На этапе тестирования прореживание не производится; вместо этого выходные значения уровня уменьшаются на коэффициент, равный коэффициенту прореживания, чтобы компенсировать разницу в активности признаков на этапах тестирования и обучения. 
В языке Python слой выравнивания кодируется следующим образом:
tf.keras.layers.Dropout(rate, noise_shape=None, seed=None, **kwargs)
rate – процент признаков, приравненных к нулю
3.3 Алгоритмы оптимизации нейросетей
3.3.1 Градиентный спуск
Воспользуемся формулой Тейлора для ‖ℎ‖=1 (направления спуска):

Мы хотим уменьшить значение функции, то есть:

При  имеем  Более того, мы хотим наискорейшего убывания, поэтому это скалярное произведение хочется минимизировать. Сделаем это при помощи неравенства Коши-Буняковского:

Равенство в неравенстве Коши-Буняковского достигается при пропорциональности аргументов, то есть:

Тогда пусть  – начальная точка градиентного спуска. Тогда каждую следующую точку мы выбираем следующим образом:

где  – это размер шага
Выбираем размер шага так, чтобы как можно сильнее уменьшить функцию:

Алгоритм продолжается до тех пор, пока мы не достигнем нужного нам качества:

За k шагов мы достигнем точности:


3.3.2 Стохастический градиентный спуск
Рассмотрим функцию вида:

где сумма проходится по всем объектам выборки. Заметим, что это усреднение –по сути взятие матожидания. Таким образом, мы говорим, что наша функция выглядит как

где  равномерно распределена по обучающей выборке. Посчитаем градиент такой функции и получим:

Подменим матожидание на его несмещенную Монте-Карло оценку. Получается то, что можно назвать стохастическим градиентом:

Таким образом, мы подменили вычисление градиента по всей выборке вычислением по случайной подвыборке. Подвыборку  принято называть батчем, а число  – размерном батча.
Мы воспользовались следующим приёмом: сначала перемешали нашу выборку, а затем будем рассмотрели последовательно блоки по  элементов выборки. Когда мы просмотрели всю выборку – перемешиваем еще раз и повторяем проход. Очередной проход по обучающей выборке называется эпохой. 
Точность модели через k-шагов:

где дисперсия стохастического градиента,  – константа сильной выпуклости. 
3.3.3 Adagrad
Рассмотрим первый алгоритм, который является адаптацией стохастического градиентного спуска. Зафиксируем – исходный коэффициент скорости обучения. Затем напишем следующую формулу обновления:

Идея заключается в том, что если мы вышли на плато по какой-то координате и соответствующая компонента градиента начала затухать, то нам нельзя уменьшать размер шага слишком сильно, поскольку мы рискуем на этом плато остаться, но в то же время нужно уменьшать, потому что это плато может содержать оптимум. При этом если градиент долгое время довольно большой, то это может быть знаком, что нам нужно уменьшить размер шага, чтобы не пропустить оптимум. Поэтому мы стараемся компенсировать слишком большие или слишком маленькие координаты градиента.

Рис 6. Зависимость объема потерь от скорости обучения и числа эпох
3.3.4 RMSProp
Модифицируем предыдущую идею: будем не просто складывать нормы градиентов, а усреднять их в скользящем режиме:


Такой выбор позволяет учитывать историю градиентов, но при этом удалось снизить скорость изменения размера шага.
3.3.5 Adam
Объединяет в себе идеи двух предыдущих алгоритмов оптимизации:



В этом алгоритме подбирается лишь один гиперпараметр альфа – коэффицент скорости обучение. Остальн , и  – оставляют равными 0.9, 0.99 и 10-8 соответственно. 
Зачастую, при начале работы с реальными данными начинают со значения альфа равного 3*10-4, но иногда выбирать и более высокий (на 1-2 порядка) начальный показатель 
Также стоит помнить, что Adam требует хранения как параметров модели, так и градиентов, накопленного импульса и нормировочных констант. То есть достижение более быстрой сходимости достигается за счет больших объемов памяти. Кроме того, при продолжении обучения модели необходимо восстановить из чекпоинта не только веса модели, но и накопленные параметры Adam. В противном случае оптимизатор начнёт сбор всех своих статистик с нуля, что может сильно сказаться на качестве дообучения. То же самое касается вообще всех описанных выше методов, так как каждый из них накапливает какие-то статистики во время обучения.
3.3.6 Классификатор на основе случайного леса
Случайный лес (Random Forest) - это алгоритм машинного обучения, который используется для решения задач классификации, регрессии и кластеризации. Он состоит из нескольких деревьев решений, которые используются для принятия коллективного решения о классификации объекта. 
Принцип работы классификатора случайного леса заключается в построении нескольких деревьев решений на основе случайных выборок данных в обучающей выборке и случайных выборок признаков (столбцов) для каждого дерева. Каждое дерево строится по индивидуальной схеме, определяющей, какие признаки и пороги следует использовать для каждого разделения данных на каждом узле дерева. Для каждого дерева случайного леса проходит процесс «обучения», при котором каждый узел решающего дерева разбивается на два дочерних узла путем выбора оптимального предиката на основе меры неопределенности (как правило, информационный критерий Джини или энтропийный критерий). Этот процесс повторяется до достижения заданного критерия остановки (например, глубины дерева). Вес узлов решающего дерева определяется на основе важности соответствующих признаков. Для классификации новых данных каждое решающее дерево в случайном лесу возвращает метку класса на основе предиката на каждом узле. Затем количество голосов, отданных деревьями на каждую метку класса, подсчитывается и выдается метка класса, которая получила наибольшее количество голосов. Весь алгоритм можно представить следующей схемой:

Рис 7. Схема алгоритма классификатора случайного леса
 1. Создание выборки с возвращением: на каждой итерации происходит выборка из обучающей выборки случайным образом. 
2. Создание случайного набора признаков: на каждой итерации происходит выборка случайного подмножества из общего списка признаков. В случае данных, где количество признаков много, этот способ позволяет использовать более устойчивые и надежные признаки, в отличие от тех, которые можно получить в изучаемом наборе данных без обработки.
3. Для каждой выборки и набора признаков строится дерево решений. Этот этап называется бэггингом. Алгоритм построения дерева решений может использоваться обычный алгоритм CART (Classification and Regression Trees), или другие модификации.
4. Строится композиция деревьев решений, путем усреднения результатов, полученных каждым деревом при классификации. В результате получается решение - объекты классифицируются на основе наиболее часто встречающегося класса. Однако процесс построения случайного леса не ограничивается только оценками метрик качества. Также важно понимать, как каждый признак влияет на данную модель. Оценка важности переменных происходит на основе уменьшения неопределенности в данных, так называемой методикой дерева, где каждый признак оценивается по вкладу в информационный выигрыш. Математически, оценка важности переменных может основываться на S-значениях. S-значения позволяют оценить вклад каждого признака в общую дисперсию модели случайного леса. Их можно вычислить, используя "Mean Decrease Impurity" - среднее уменьшение неопределенности на основе прогнозов внутренних узлов каждого дерева. Эта мера может быть использована для определения того, какие признаки влияют на модель больше всего. 
Также можно использовать метод "Mean Decrease Accuracy", который определяет важность признаков, основываясь на снижении точности по различным деревьям случайного леса, когда отдельный признак был бы случайным образом перемешан. Чем более сильно падает точность при перемешивании данного признака, тем большее значение он имеет для данной модели. Итак, оценка важности переменных в случайном лесе производится путем изучения, как важен каждый признак для каждого дерева и какова средняя важность этого признака в ходе работы всего алгоритма. Это позволяет определить наиболее важные признаки в данных и что такое влияние на результаты классификации и регрессии, и использовать эти знания при анализе других моделей.
В языке Python классификатор случайного леса кодируется следующим образом:
sklearn.ensemble.RandomForestClassifier(n_estimators=100,
criterion='gini’,
max_depth=None,
min_samples_split=2,
min_samples_leaf=1,
min_weight_fraction_leaf=0.0,
max_features='sqrt’,
max_leaf_nodes=None,
min_impurity_decrease=0.0,
bootstrap=True,
oob_score=False,
n_jobs=None,
random_state=None
verbose=0,
warm_start=False,
class_weight=None,
ccp_alpha=0.0,
max_samples=None)

n_estimators – количество деревьев в лесу

criterion – функция измерения качества разделения. Можем использовать критерий Джини (gini), энтропию (entropy) или логарифмическую потерю (log_loss)
Критерий Джини считается по этой формуле:

Энтропийный критерий:

Логарифмическая потеря:


где – предсказанная вероятность,  – истинный класс наблюдения

max_depth – максимальная глубина дерева. Если не задана, то узлы расширяются до тех пор, пока все листья не станут «чистыми» или пока все листья не будут содержать меньше образцов min_samples_split.

min_samples_split - минимальное количество выборок, требуемое для разделения внутреннего узла

min_samples_leaf – минимальное количество выборок, которое требуется для конечного узла. Точка разделения на любой глубине будет учитываться только в том случае, если она оставляет по крайней мере min_samples_leaf обучающих выборок в каждой из левой и правой ветвей. Это может привести к сглаживанию модели, особенно при регрессии.

max_features – количество функций, которые следует учитывать при поиске наилучшего разделения.

n_jobs – количество активных ядер процессора (-1 – задействованы все ядра процессора)

random_state – начальное значение для рандомизации выборки

class_weight – сбалансировать классы, если количество объектов одного из них сильно превосходит количество объектов другого

3.3.7 Математическая модель дерева принятия решений

В основе обучение отдельного дерева принятия решений лежит алгоритм CART – Classification and Regression Trees. Одной из основных идей алгоритма CART является неопределенность в узлах, которая может быть сведена к разнообразию примеров. На примере узла, содержащего 50 примеров каждого из двух классов, можно понять, что разбиение данных на две группы 40:5 и 10:45 интуитивно снизит неопределенность узла. Полностью её можно убрать, создав группы 50:0 и 0:50. Формализацией этой идеи является использование индекса Gini, который определяется для набора данных T с n классами. Если набор данных T содержит данные n классов, тогда индекс Gini определяется следующим образом:

где  – вероятность (относительная частота) класса i в наборе T. Если набор T разбивается на две части T1 и T2 с числом примеров в каждом N1 и  N2 соответственно, тогда показатель разбиения будет равен:

Наилучшим считается то разбиение, для которого Ginisplit(T) минимально. Обозначим N — число примеров в узле — предке, L, R — число примеров соответственно в левом и правом потомке, li и ri — число экземпляров i-го класса в левом и правом потомке. Тогда качество разбиения оценивается по следующей формуле:

Преобразуем формулу, уменьшив объем вычислений:

Домножим обе части выражения на N. Умножение выражения на константу не влияет на минимизацию:



В итоге, лучшим будет то разбиение, для которого данная величина максимальна. Таким образом, при построении «дерева решений» по методу CART ищется такой вариант ветвления, при котором максимально уменьшается значение показателя Ginisplit(T).
Отметим достоинства и недостатки данного алгоритма:
Достоинства:
1. Для применения алгоритма CART нет необходимости заранее выбирать переменные, который будут участвовать в анализе: переменные отбираются непосредственно во время проведения анализа на основании значения индекса Gini.
2. CART легко борется с выбросами: механизм «разбиения», заложенный в алгоритме просто помещает «выбросы» в отдельный узел, что позволяет очистить имеющиеся данные от шумов.
3. Для применения этого алгоритма не надо принимать в расчет никаких предположений или допущений перед проведением анализа.
4. Высокая скорость работы алгоритма.
Недостатки:
1. Деревья решений, предложенные алгоритмом, не являются стабильными: результат, полученный на одной выборке, бывает не воспроизводим на другой (дерево может увеличиваться, уменьшаться, включать другие предикторы и т.д.)
2. В случае, когда необходимо построить дерево с более сложной структурой, лучше использовать другие алгоритмы, так как CART может не идентифицировать правильную структуру данных.

3.3.8 XGBoost
Библиотека xgboost – вычислительно эффективная реализация градиентного бустинга над деревьями принятия решений. Рассмотрим для примера задачу регрессии:

 – обучающая выборка
K – количество деревьев в ансамбле
 – k-е дерево ансамбля как функция
 – весь ансамбль как функция
 – выбранная пользователем функция потерь
 – количество листьев к k-м дереве ансамбля
 – вектор, составленный из выходных значений на всех листьях k-го дерева
В XGBoost суммируем ответы по всем деревьям ансамбля:

Суммарная функция потерь выглядит следующим образом:

Здесь –  и  – гиперпараметры. Первое слагаемое - это основная функция потерь, второе слагаемое штрафует деревья за слишком большое количество листьев, третье слагаемое за слишком большие предсказания. Третье слагаемое является нетипичным в машинном обучении. Оно обеспечивает то, что каждое дерево вносит минимальный вклад в результат. Функция потерь используется при построении каждого следующего дерева, то есть функция потерь оптимизируется по параметрам лишь последнего дерева, не затрагивая предыдущие. Для минимизации потерь используется метод второго порядка, то есть рассчитываются не только производные, но и вторые производные функции потерь по предсказаниям предыдущих деревьев. При поиске каждого нового разделяющего правила, для каждого признака перебираются не все возможные значения порога, а значения с определенным шагом. Для этого на признаке рассчитывается набор персентилей, используя статистику из обучающего датасета. Поиск оптимального порога выполняется только среди этих персентилей. Это позволяет существенно сократить время перебора и ускорить обучение. Для работы с пропущенными значениями в каждом решающем правиле определяется ветвь, в которую будут отправлены объекты с пропущенным значением данного признака.
Однако основной ценностью библиотеки XGBoost является эффективная программная реализация. За счет разных оптимизаций, таких как эффективная работа с пропущенными значениями, поиск порога только среди персентилей, оптимизация работа с кэшем и распределенное обучение, достигается выигрыш в десятки или даже сотни раз по сравнению с наивной реализацией.

3.4 Метрики качества моделей
Метрики качества в машинном обучении являются средством оценки целевых характеристик модели. Эти метрики используются для определения того, насколько хорошо модель работает на новых данных, и определения того, какие характеристики могут быть улучшены. В этом статье мы рассмотрим ряд распространенных метрик качества и объясним, как они работают, а также приведем примеры использования этих метрик. 
1. Точность (Accuracy): Точность - это одна из самых распространенных метрик качества в машинном обучении. Она измеряет, как часто модель предсказывает правильный класс для данных. Формулу точности можно записать следующим образом: Точность = (Количество верных предсказаний) / (Всего элементов в выборке) Точность может быть неэффективной метрикой для классификационных моделей, если классы несбалансированы. Для примера, если в выборке 90% объектов относятся к классу А, а только 10% - к классу B, модель может показать точность выше 90%, но быть нерадостной, если она никогда не угадывает класс B. В этих случаях рекомендуется использовать другие метрики, такие как матрицы ошибок и мера F1. 
2. Матрица ошибок (Confusion matrix): Матрица ошибок позволяет проанализировать количество верных и ошибочных предсказаний модели в классификационной задаче. Матрица ссылается на истинные и предсказанные метки каждого класса и может выглядеть следующим образом: 

Рис 8. Матрица ошибок
Используя эту матрицу, разработчик может определить метрики как расчет точности, полноты, F-меры и др. 
3. Точность (Precision) и Полнота (Recall): 
Точность и Полнота - это две метрики, которые учитывают истинно-положительные, ложно-положительные и ложно-отрицательные результаты модели. Математически эти метрики представляют собой следующее соотношение: 


Точность измеряет, насколько точна модель при выборе положительного класса ИЛИ количество объектов, которые модель действительно относит к истинному положительному классу из всех объектов, которые были классифицированы как положительные. Полнота измеряет, сколько истинно положительных результатов охватывает модель. При этом она также учитывает отрицательные результаты различных метрик, таких как ложноотрицательный. 
4. F1-мера (F1-score):
Данный показатель объединяет в себе две метрики качества модели: точность и полноту:











































4. Содержательная постановка задачи

Машинное обучение является областью специализации в рамках данной работы.
Основная цель КНИР заключается в разработке веб-приложения, в основе которого заключаются модели машинного обучения для диагностики 7 заболеваний. Для этого необходимо выполнить следующие задачи:

Определение математического класса задач;
Определение подходящих моделей машинного обучения;
Поиск датасетов для обучения моделей;
Создание моделей:
Определение структуры моделей;
Выбор гиперпараметров;
Выбор признаков;
Реализовать сохранение наилучших весов и структур модели в формате файлов для возможности повторного воспроизведения результатов.
Обучение моделей на обучающей выборке, оптимизация гиперпараметров;
Оценка точности моделей, выбор наилучших моделей;
Тестирование моделей;
Разработка бакэнда для веб-приложения;
Реализация таблицы для ввода данных пользователя
Реализация функции для отправки результатов исследования по электронной почте;
Встраивающие обученных моделей в серверную часть приложения;
Разработка веб-интерфейса для удобства пользователя;
Запуск веб-приложения;
Развертывание веб-приложения на сервере;
Тестирование работы веб-приложения;

Функциональная схема может быть представлена следующим образом:
































5. Математическая постановка задачи. 

Множество признаков: Пусть X представляет собой множество признаков, где каждый пациент представлен вектором признаков x ∈ X.
Множество меток: Пусть Y представляет собой множество меток, где каждый пациент имеет соответствующую метку y ∈ Y, относящуюся к определенному заболеванию.
Обучающая выборка: Пусть D = {(x_1, y_1), (x_2, y_2), ..., (x_N, y_N)} представляет собой обучающую выборку, состоящую из пар признаков и меток, где каждый элемент (x_i, y_i) соответствует i-му пациенту.
Модели машинного обучения: Пусть M = {M_1, M_2, ..., M_7} представляет собой множество моделей машинного обучения, где каждая модель M_j, j = 1, 2, ..., 7, является моделью для классификации определенного заболевания.
Функции потерь: Пусть L = {l_1, l_2, ..., l_7} представляет собой множество функций потерь, используемых для обучения моделей, где каждая функция потерь l_j, j = 1, 2, ..., 7, измеряет расхождение между предсказанными метками и истинными метками.
Обучение моделей: Для каждой модели M_j, j = 1, 2, ..., 7, и соответствующей функции потерь l_j, задача состоит в нахождении оптимальных параметров модели, которые минимизируют функцию потерь на обучающей выборке D. Математически, это может быть записано как:
min_{θ_j} Σ_{i=1}^N l_j(M_j(x_i; θ_j), y_i)
где θ_j представляет параметры модели M_j, M_j(x_i; θ_j) обозначает предсказанную метку для признаков x_i с использованием модели M_j, а y_i обозначает истинную метку для признаков x_i.
Тестирование моделей: После обучения моделей M_j, j = 1, 2, ..., 7, производится тестирование на отложенной тестовой выборке. Метрики качества, такие как точность, полнота и F-мера, используются для оценки производительности моделей. Математически, это может быть записано как: 

Тестовая выборка: Пусть T = {(x'_1, y'_1), (x'_2, y'_2), ..., (x'_M, y'_M)} представляет собой тестовую выборку, состоящую из пар признаков и меток, где каждый элемент (x'_i, y'_i) соответствует i-му пациенту, который не был использован при обучении моделей.

Оценка производительности моделей: Для каждой модели M_j, j = 1, 2, ..., 7, производится оценка производительности на тестовой выборке T. Метрики качества, такие как точность, полнота, F-мера и др., используются для измерения эффективности каждой модели. Математически, это может быть записано как:

P(M_j) = E(M_j, T)

где PM_j) представляет оценку производительности модели M_j на тестовой выборке T, а E(M_j, T) обозначает функцию оценки, которая вычисляет метрики качества для модели M_j на тестовой выборке T.

Таким образом, оценка производительности моделей производится на отложенной тестовой выборке, и метрики качества используются для сравнения и оценки эффективности каждой модели.













6. Использование методов и средств информационных технологий
Для работы с данными и реализации моделей машинного обучения был использован язык программирования Python. Ом имеет большое количество библиотек для анализа данных и обучения моделей машинного обучения, что позволяет не реализовывать их с нуля. В качестве среды для разработки был использован jupyter-lab, так как он имеет широкий функционал запуска кода в изолированных ячейках и визуализации данных. 

Для работы с датасетами использовались следующие библиотеки:
Numpy - предоставляет интерфейс для матричного предоставления данных;
Matplotlib - модуль peplos позволяет визуализировать данные;
Sklearn - используется для препроцессинга данных. 
Plotly - библиотека для визуализации данных. 
OpenCV - различные операции для обработки изображений. 
Seaborn - для визуализации данных. 

Для создания и обучения моделей использованы:
Tensorflow - модуль keras предоставляет интерфейс для создания сверточных нейронных сетей;  
Для создания веб-приложения использовался фреймворк Flask использующий набор инструментов Werkzeug, а также шаблонизатор Jinja2. 

Разработка веб-интерфейса приложения была произведена с использованием языков HTML, CSS, JavaScript и фреймворк Bootstrap. 































7. Проведенные исследования и анализ полученных результатов

7.1. Работа с данными
7.1.1 Поиск и формирование датасетов
Определение заболеваний: Сначала был проведен анализ и исследование для определения списка заболеваний, для которых требуется найти соответствующие датасеты. Этот список включал опухоли ГМ, рак молочной железы, COVID-19, болезнь Альцгеймера, диабет и заболевания сердца.
Поиск в открытых источниках: После определения заболеваний, был проведен поиск в открытых источниках данных, доступных в интернете. Были использованы публичные репозитории, базы данных, медицинские ресурсы, а также онлайн-сообщества, специализирующиеся на медицинских исследованиях. Примерами таких ресурсов являются PubMed, kaggle и другие.
Корректировка датасетов: После обнаружения соответствующих датасетов, был выполнен их анализ и оценка. При этом проверялась соответствие требованиям, таким как размер данных, типы признаков, доступность меток и другие характеристики. Если необходимо было провести корректировки данных, например, удалить неподходящие признаки или провести очистку данных от выбросов, то эти действия выполнялись в соответствии с требованиями дипломной работы.
Проверка доступности и лицензирования: Была проверена доступность датасетов для использования в дипломной работе, а также проверены лицензионные ограничения, если они применяются. Выбранные датасеты доступны в открытом доступе и могут быть использованы в соответствии с требованиями исследования.
Документирование и выбор датасетов: После проведения поиска, анализа и корректировки датасетов, был осуществлен выбор наиболее подходящих датасетов для каждого из заболеваний. Каждый выбранный датасет был документирован с указанием его источника, характеристик и основных параметров.
Загрузка и предобработка данных: После выбора наиболее подходящих датасетов для каждого из заболеваний, был осуществлен их загрузка в рабочую среду. Датасеты были загружены в соответствующие программные среды или инструменты для обработки данных, такие как Python с использованием библиотеки NumPy.

После загрузки данных была проведена предварительная обработка, заполнение пропущенных значений, масштабирование признаков и преобразование категориальных признаков в числовые значения. Предобработка данных была выполнена в соответствии с требованиями каждого заболевания и особенностями выбранных датасетов.

Кроме того, при предобработке данных были применены специфические методы или алгоритмы, связанные с каждым заболеванием.

В результате проведенного поиска и предобработки данных были получены готовые датасеты, которые могли быть использованы для разработки моделей анализа каждого из 7 заболеваний в рамках дипломной работы.

7.2 Обучение моделей
Был произведен выбор алгоритмов и архитектуры моделей: Для каждого из заболеваний был выбран подходящий алгоритм машинного обучения или глубокого обучения, а также определена соответствующая архитектура модели.
Создание и компиляция моделей: Соответствующие модели были созданы с использованием выбранного фреймворка машинного обучения, например TensorFlow или Keras. Затем модели были скомпилированы с оптимизатором, функцией потерь и метриками для оценки производительности моделей.
Обучение моделей: Процесс обучения моделей был запущен на обучающих данных. Для каждой эпохи обучения модели обновляли свои веса на основе градиентов функции потерь с использованием выбранного оптимизатора. При необходимости применялись методы регуляризации или улучшения процесса обучения, такие как аугментация данных.
Оценка производительности моделей: После завершения процесса обучения моделей оценивалась их производительность на тестовых данных. Используя заранее определенные метрики качества, такие как точность (accuracy), полнота (recall), точность предсказания и другие, оценивалась способность моделей классифицировать и диагностировать соответствующие заболевания.
Настраивание гиперпараметров: При необходимости проводилось настраивание гиперпараметров моделей для достижения оптимальной производительности. Это включало изменение параметров, таких как скорость обучения, количество скрытых слоев, количество нейронов в слоях, коэффициенты регуляризации и другие. Настраивание гиперпараметров выполнялось путем перебора различных значений или с использованием алгоритмов оптимизации, таких как GridSearch или RandomizedSearch.
Оценка и сравнение моделей: После обучения и настройки моделей были проанализированы и сравнены их результаты. Используя метрики производительности и результаты на тестовых данных, модели были оценены на их способность классифицировать и диагностировать соответствующие заболевания. Были проведены сравнительные анализы производительности различных моделей для каждого из заболеваний.
Итеративное улучшение моделей: В случае неудовлетворительных результатов или необходимости улучшения производительности, были предприняты дополнительные шаги для итеративного улучшения моделей. Это могло включать изменение архитектуры моделей, использование более сложных алгоритмов, повышение объема данных или проведение дополнительной предобработки данных.
Документация результатов: После завершения обучения моделей и анализа их результатов была составлена документация, в которой были описаны подробности каждой модели, ее архитектура, выбранные гиперпараметры, результаты производительности и выводы о применимости модели для анализа соответствующего заболевания.

7.3 Тестирование моделей
Тестирование моделей производилось на данных которые не были использованы при обучении. Результаты получились более чем удовлетворительные (выше 75% в каждой модели). Также проводились тесты с библиотекой XGBoost. Но от нее пришлось отказаться в связи более низкой точностью. 

7.4 Разработка веб-приложения
Веб-приложение разрабатывалась на базе фреймворка Flask и используя языки такие как HTML, CSS, JavaScript. Фреймворк Bootstrap использовался для реализации стилей. Также была добавлена функция для того, чтобы если пользователь захотел то ему веб-приложение может отправить результат на его электронную почту. 
Также была добавлена кнопка о нас, чтобы можно было донести до пользователя информацию что делает веб-приложение. 


















































Рисунок 1. Интерфейс приложения “МедСмарт”





















8. Выводы
В рамках данной работы был проведен аналитический обзор литературы6 посвященной диагностике различных заболеваний при помощи машинного обучения. Были проведен анализ решений которые существуют. В результате были обучены и сделаны свои модели на основе машинного обучения. 

В процессе решения поставленной задачи были осуществлены следующие виды деятельности: 
Проанализирована индустрия машинного обучения в медицине;
Сформулированы содержательная и математическая постановки задачи;
Выбраны и обработаны датасеты;
Обучены модели машинного обучения;
Протестированы готовые модели;
Оптимизированы различными методами для достижения наилучшей точности;
Было разработано веб-приложение, куда были встроены обученные модели;
Произведена установка веб-приложения на сервер, для того чтобы любой пользователь мог зайти в него через браузер используя сеть Интернет

Подводя итоги, можно говорить, что машинное обучение активно тестируется в области здравоохранения. Нынешние решения позволяют обучить модель, чтобы достигать удовлетворительной точности при исследовании различных заболеваний. 
Каждая модель в данном веб-приложении имела более 75% точности распознавания. Были применены различные методы для обучения моделей, чтобы можно было подойти к каждому заболеванию с особым вниманием. 
Данное приложение можно оптимизировать и улучшать в своем функционале. Можно использовать более продвинутые технологии машинного обучения. Также можно увеличивать количество данных в датасете, использовать более сложные технологии оптимизации данных. 
Можно добавлять новые функции в основе которых лежит машинное обучение. Допустим можно добавить технологию для сегментации слоев сетчатки глаза, для дальнейшего анализа и помощи в лечении пациентов. Данное приложение с более высоким показателем точности смогло бы помочь оптимизировать работу врачей и специалистов в системе здравоохранения. 



























9. Список использованных источников
Васильев, А. (2018). Прикладное машинное обучение с использованием Python. М.: ДМК Пресс. Стр. 1-256.
Шолом, А., Бен-Ган, И., Лайт, Д. (2019). Питон для анализа данных. М.: Вильямс. Стр. 1-600.
Иванов, В., Солодовников, В. (2019). Машинное обучение и большие данные в медицине и биологии. М.: Ленанд. Стр. 1-286.
Колесников, А. (2020). Python и машинное обучение. М.: Эксмо. Стр. 1-480.
Метлов, А. (2021). Flask. Создание веб-сайтов на Python. М.: Эксмо. Стр. 1-320.
Захаров В.А., Ли М.С. Машинное обучение и анализ данных. — М.: МЦНМО, 2019. - 424 стр.
Николенко С. И., Кадурин А. А., Архангельская Е. О. Глубокое обучение. Погружение в мир нейронных сетей. — М.: ДМК Пресс, 2018. - 456 стр.
Иванов С.В. Flask: создание веб-сайтов на Python. — СПб.: БХВ-Петербург, 2020. - 128 стр.
Гринько А.В., Константинов А.О., Панкратова Е.С. Машинное обучение и анализ больших данных в медицине. - М.: Издательство "Наука", 2017. - 354 стр.
Амосов А.П. Введение в машинное обучение. - М.: Издательство "Наука", 2019. - 312 стр.
Литвинов Ю.А., Успенский В.А. Теория вероятностей и математическая статистика: Основы машинного обучения. - М.: Издательство "Наука", 2017. - 480 стр.
Боровиков В.П., Боровиков И.В. STATISTICA: Статистический анализ и обработка данных в среде Windows. - М.: Финансы и статистика, 2003. - 608 стр.
Николенко С. И., Ковалеров А. В., Кривов Г. В. Машинное обучение для людей. — СПб.: Питер, 2019. - 320 стр.
Миронова В.Л., Черничкин В.Л., Деркач А.А. Применение машинного обучения в медицине: проблемы и перспективы. - М.: Издательство "Наука", 2018. - 340 стр.
Котельников И.В., Котельникова Ю.И. Разработка веб-приложений в среде Python. Создание веб-сайтов с помощью Flask и Django. - СПб.: БХВ-Петербург, 2020. - 512 стр.
Goodfellow, I., Bengio, Y., Courville, A. (2016). Deep Learning. MIT Press. Стр. 1-775.
Bishop, C. M. (2006). Pattern Recognition and Machine Learning. Springer. Стр. 1-738.
Hastie, T., Tibshirani, R., Friedman, J. (2009). The Elements of Statistical Learning: Data Mining, Inference, and Prediction. Springer. Стр. 1-745.
Grus, J. (2015). Data Science from Scratch: First Principles with Python. O'Reilly Media. Стр. 1-330.
McKinney, W. (2017). Python for Data Analysis. O'Reilly Media. Стр. 1-544.
Flask Web Development with Python Tutorial. (2023). Flask Documentation. Стр. 1-200.












10. Приложения
В данном пункте будут приведены фрагменты кода с документированием. На данный момент код документируется и приложения будут вставлены чуть позже. 
