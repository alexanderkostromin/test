# -*- coding: utf-8 -*-
"""Covid Detection.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1ncpuYS_PO-wPY0owf9KJpfF4lJ5rxe4X
"""

from tensorflow import keras
from tensorflow.keras.layers import Conv2D,MaxPool2D,Dropout,Flatten,Dense
from tensorflow.keras.models import Sequential
from tensorflow.keras.preprocessing import image
import matplotlib.pyplot as plt

model = Sequential()
# Создаем стек слоев, каждый из которых имеет один входной и один выходной вектор (последовательная модель)

model.add(Conv2D(32,(3,3),activation='relu',input_shape=(224,224,3)))
#Задаем слой 2D свертки. 
#Первый аргумент - представляет количество фильтров, на основе которых обучается сверточный уровень, так называемая глубина тензора
#Второй аргумент - размер ядра фильтра. В данном случае он представляет собой квадратную матрицу 3*3
#Третий аргумент - функция активации, в нашем случае - RELU. (max(arg, 0))
#Четвертый аргумент - настройка нулевого отступа, в нашем случае 'same'

model.add(Conv2D(64,(3,3),activation='relu'))
#Задаем слой 2D свертки. 
#Первый аргумент - представляет количество фильтров, на основе которых обучается сверточный уровень, так называемая глубина тензора
#Второй аргумент - размер ядра фильтра. В данном случае он представляет собой квадратную матрицу 3*3
#Третий аргумент - функция активации, в нашем случае - RELU. (max(arg, 0))
#Четвертый аргумент - настройка нулевого отступа, в нашем случае 'same'

model.add(MaxPool2D(pool_size=(2,2)))
# Операция выбора максимального значения из соседних, "агрессивное" уменьшение разрешения карты признаков 
# Первый аргумент - определение "окна", из которого выбирается максимальное значение

model.add(Dropout(0.25))
# Данный слой зануляет случайно выбранные признаки
# Первый аргумент соответствует доле отбрасываемых признаков

model.add(Conv2D(64,(3,3),activation='relu'))
#Задаем слой 2D свертки. 
#Первый аргумент - представляет количество фильтров, на основе которых обучается сверточный уровень, так называемая глубина тензора
#Второй аргумент - размер ядра фильтра. В данном случае он представляет собой квадратную матрицу 3*3
#Третий аргумент - функция активации, в нашем случае - RELU. (max(arg, 0))
#Четвертый аргумент - настройка нулевого отступа, в нашем случае 'same'

model.add(MaxPool2D(pool_size=(2,2)))
# Операция выбора максимального значения из соседних, "агрессивное" уменьшение разрешения карты признаков 
# Первый аргумент - определение размера "окна", из которого выбирается максимальное значение

model.add(Dropout(0.25))
# Данный слой зануляет случайно выбранные признаки
# Первый аргумент соответствует доле отбрасываемых признаков

model.add(Conv2D(128,(3,3),activation='relu'))
#Задаем слой 2D свертки. 
#Первый аргумент - представляет количество фильтров, на основе которых обучается сверточный уровень, так называемая глубина тензора
#Второй аргумент - размер ядра фильтра. В данном случае он представляет собой квадратную матрицу 3*3
#Третий аргумент - функция активации, в нашем случае - RELU. (max(arg, 0))
#Четвертый аргумент - настройка нулевого отступа, в нашем случае 'same'

model.add(MaxPool2D(pool_size=(2,2)))
# Операция выбора максимального значения из соседних, "агрессивное" уменьшение разрешения карты признаков 
# Первый аргумент - определение размера "окна", из которого выбирается максимальное значение

model.add(Dropout(0.25))
# Данный слой зануляет случайно выбранные признаки
# Первый аргумент соответствует доле отбрасываемых признаков

model.add(Flatten())
# Преобразует входные данные в один большой одномерный массив

model.add(Dense(64,activation='relu'))
# Обычный слой нейронной сети с плотным соединением
# Первый аргумент -  Положительное число. Размерность выходного пространства. Он определяет, сколько нейронов будет в этом слое
# Второй аргумент - функция активации. В нашем случае - RELU. (max(arg, 0))

model.add(Dropout(0.5))
# Данный слой зануляет случайно выбранные признаки
# Первый аргумент соответствует доле отбрасываемых признаков

model.add(Dense(1,activation='sigmoid'))
# Обычный слой нейронной сети с плотным соединением
# Первый аргумент -  Положительное число. Размерность выходного пространства. Он определяет, сколько нейронов будет в этом слое
# Второй аргумент - функция активации. В нашем случае - sigmoid. (1 / [1 + e^(-x)])

model.compile(loss=keras.losses.binary_crossentropy,optimizer='adam',metrics=['accuracy'])
# Настраиваем модель для обучения
# Второй аргумент - оптимизатор
# Первый аргумент - задание функции потерь
# Третий аргумент метрики качеста модели (точность)


model.summary()
# контроль размерности выходных данных

train_datagen = image.ImageDataGenerator(rescale = 1./255,
                                         shear_range = 0.2,
                                         horizontal_flip = True,
                                         zoom_range = 0.2)

val_datagen = image.ImageDataGenerator(rescale=1./255)

training_data = train_datagen.flow_from_directory('Train',
                                                  target_size=(224,224),
                                                  class_mode='binary',
                                                  batch_size=32)

val_data = val_datagen.flow_from_directory('Val',
                                           target_size=(224,224),
                                           class_mode='binary',
                                           batch_size=32)

training_data.class_indices

e = 20
hist = model.fit(training_data,
                    steps_per_epoch=8,
                    epochs = e,
                    validation_data = val_data,
                    validation_steps = 2)
# Подгонка модели

model.save('../models/covid.h5')
# Сохранение модели

train_loss = hist.history['loss']
val_loss = hist.history['val_loss']
acc = hist.history['accuracy']
val_acc = hist.history['val_accuracy']

epochs = range(1,e+1)

plt.figure(figsize=(19,8))
plt.subplot(121)
plt.plot(epochs,train_loss,label='Training loss')
plt.plot(epochs,val_loss,label='Validation Loss')
plt.title('Losses')

plt.subplot(122)
plt.plot(epochs,acc,label='Training Accuracy')
plt.plot(epochs,val_acc,label='Validation Accuracy')
plt.title('Accuracy')

plt.legend()

model.evaluate_generator(training_data)

model.evaluate_generator(val_data)

"""### Testing"""

import cv2
import os
import seaborn as sns
from tensorflow.keras.models import load_model

TP = 0
TN = 0
FP = 0
FN = 0

model = load_model('../models/covid.h5')

covid_images = os.listdir('Test/COVID')
normal_images = os.listdir('Test/NORMAL')

for i in covid_images:
    img = cv2.imread('Test/COVID/'+i)
    img = cv2.resize(img, (224, 224))
    img = img.reshape(1, 224, 224, 3)
    img = img/255.0
    pred = model.predict(img)
    if pred<0.5:
    TP+=1
    else:
    FN+=1

for i in normal_images:
    img = cv2.imread('Test/NORMAL/'+i)
    img = cv2.resize(img, (224, 224))
    img = img.reshape(1, 224, 224, 3)
    img = img/255.0
    pred = model.predict(img)
    if pred>0.5:
    TN+=1
    else:
    FP+=1
  
sns.heatmap([[TP,FP],[FN,TN]],annot=True)

